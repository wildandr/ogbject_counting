










































































cv2.destroyAllWindows()# Close all OpenCV windowsout.release()cap.release()# Release video capture and writer objects    out.write(frame)    # write frame to output video    show_frame_in_notebook(frame)    frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)    # annotate and display frame    labels = [f"{model.model.names[class_id]} {confidence:0.2f}" for _, _, confidence, class_id, _ in detections]    detections = Detections.from_yolov8(results)    results = model(frame, verbose=False, device='cpu', conf=.015, iou=.02, imgsz=1280)[0]    # model prediction on single frame and conversion to supervision Detections        break    if not ret:    ret, frame = cap.read()while cap.isOpened():# Process video framesmask_annotator = MaskAnnotator(color=palette, thickness=2)box_annotator = BoxAnnotator(color=palette, thickness=2, text_thickness=2, text_scale=1)# Create annotatorspalette = ColorPalette()# Create color paletteout = cv2.VideoWriter("output.mp4", cv2.VideoWriter_fourcc(*"mp4v"), fps, (frame_width, frame_height))# Create video writer objectframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))fps = cap.get(cv2.CAP_PROP_FPS)# Get video properties    print("Error opening video file")if not cap.isOpened():# Check if video opened successfullycap = cv2.VideoCapture(VIDEO_PATH)# Create video capture objectpredictor = SamPredictor(sam)sam.to(device=DEVICE)sam = sam_model_registry[MASK_MODEL_TYPE](checkpoint=MASK_MODEL_PATH)# Create SAM modelmodel = YOLO(MODEL_PATH)# Create YOLO modelMASK_MODEL_PATH = "sam_vit_h_4b8939.pth"MASK_MODEL_TYPE = "vit_h"MODEL_PATH = "yolov8n-seg.pt"DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")VIDEO_PATH = "video.mp4"# Constantsfrom supervision.tools.segment import MaskAnnotatorfrom supervision.tools.detections import Detections, BoxAnnotatorfrom supervision.notebook.utils import show_frame_in_notebookfrom supervision.geometry.core import Positionfrom supervision.draw.color import ColorPalettefrom ultralytics import YOLOfrom segment_anything import sam_model_registry, SamPredictorimport torchimport numpy as npimport supervision as svimport cv2